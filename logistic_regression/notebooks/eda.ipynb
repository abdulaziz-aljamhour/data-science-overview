{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "import pandas   as pd\n",
    "import numpy    as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from typing import Tuple, Annotated\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "load_dotenv()\n",
    "os.chdir('..')\n",
    "\n",
    "KAGGLE_USERNAME = os.getenv('KAGGLE_USERNAME')\n",
    "PROJECT_ROOT = os.getenv('PROJECT_ROOT')\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sms-spam-collection-dataset.zip to /home/azdt/code_zone/data_science/data-science-overview/logistic_regression/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211k/211k [00:00<00:00, 317kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download spam data set\n",
    "dataset_slug = \"uciml/sms-spam-collection-dataset\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, 'data')\n",
    "\n",
    "kaggle.api.dataset_download_files(\n",
    "    dataset_slug,\n",
    "    DATA_PATH,\n",
    "    unzip=True,\n",
    "    quiet=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and writing initial functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-31 22:58:38.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mLoading in spam dataset.\u001b[0m\n",
      "\u001b[32m2024-03-31 22:58:38.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mData loaded successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path_spam: str = os.path.join(DATA_PATH, 'spam.csv')\n",
    "\n",
    "def get_file_encoding(path: str) -> Annotated[str, 'file_encoding']:\n",
    "    try:\n",
    "        with open(path, 'rb') as bin_data:\n",
    "            result = chardet.detect(bin_data.read(100_000))\n",
    "    except Exception as e:\n",
    "        logger.info(\n",
    "            f'An error has occurred while trying to detect file encoding: {e}.'\n",
    "            )\n",
    "    return result['encoding']\n",
    "\n",
    "def load_data(path: str) -> Annotated[pd.DataFrame, 'df']:\n",
    "    try:\n",
    "        logger.info('Loading in spam dataset.')\n",
    "        df: pd.DataFrame = pd.read_csv(path, encoding=get_file_encoding(path)) \\\n",
    "            .iloc[:, [0, 1]]\n",
    "        logger.info('Data loaded successfully')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.info(f'An error has occurred in `load_data`: {e}.')\n",
    "\n",
    "df = load_data(path_spam)\n",
    "\n",
    "def create_mapper(df: pd.DataFrame, values: list[str]) -> Annotated[\n",
    "    dict[str, str], 'mapper']:\n",
    "    keys = df.columns\n",
    "    values: list[str] = ['label', 'message']\n",
    "    mapper = {k:v for k, v in zip(keys, values)}\n",
    "    return mapper\n",
    "\n",
    "def rename_columns(df: pd.DataFrame, mapper: dict[str, str]=None) -> Annotated[\n",
    "    pd.DataFrame, 'df_renamed']:\n",
    "    if mapper == None:\n",
    "        raise Exception('mapping dict is None')\n",
    "    else:\n",
    "        df_renamed = df.rename(mapper, axis=1)\n",
    "        return df_renamed\n",
    "    \n",
    "def update_labels(df: pd.DataFrame) -> Annotated[pd.DataFrame, \n",
    "                                                 'df_label_updated']:\n",
    "    df = df.copy()\n",
    "    label_mapper = {k:v for k,v in zip(df.label.unique(), (0, 1))}\n",
    "    df['label'] = df.label.map(label_mapper)\n",
    "    return df\n",
    "    \n",
    "mapper = create_mapper(df, 'label message'.split())\n",
    "df = rename_columns(df, mapper)\n",
    "df = update_labels(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class count normalized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     86.59\n",
       "spam    13.41\n",
       "Name: count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('class count')\n",
    "display(df.label.value_counts())\n",
    "print('class count normalized')\n",
    "display(df.label.value_counts().div(len(df)).mul(100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced classes, have to consider that while developing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>spam</td>\n",
       "      <td>For ur chance to win a å£250 wkly shopping spr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>spam</td>\n",
       "      <td>Our records indicate u maybe entitled to 5000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to the latest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>spam</td>\n",
       "      <td>Get your garden ready for summer with a FREE s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "4582  spam  For ur chance to win a å£250 wkly shopping spr...\n",
       "5190  spam  Our records indicate u maybe entitled to 5000 ...\n",
       "4726  spam  Had your mobile 10 mths? Update to the latest ...\n",
       "5147  spam  Get your garden ready for summer with a FREE s...\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can help u swoop by picking u up from wherever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>ham</td>\n",
       "      <td>tap &amp; spile at seven. * Is that pub on gas st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>ham</td>\n",
       "      <td>Haha, that was the first person I was gonna ask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm ok wif it cos i like 2 try new things. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5383</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good day to You too.Pray for me.Remove the tee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "5259   ham  Can help u swoop by picking u up from wherever...\n",
       "3265   ham  tap & spile at seven. * Is that pub on gas st ...\n",
       "4898   ham    Haha, that was the first person I was gonna ask\n",
       "112    ham  I'm ok wif it cos i like 2 try new things. But...\n",
       "5383   ham  Good day to You too.Pray for me.Remove the tee..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample_class(df: pd.DataFrame, class_label: str='spam', n: int=5) -> \\\n",
    "    Annotated[pd.DataFrame, 'df_sample']:\n",
    "    mask_class: pd.Series = df.label == class_label\n",
    "    df_sample: pd.DataFrame = df.loc[mask_class, :].sample(n)\n",
    "    return df_sample\n",
    "\n",
    "display(sample_class(df, ))\n",
    "display(sample_class(df, 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Since the main feature is textual, we need to use NLP techniques in order to encode\n",
    "nature language to numbers for logistic model.\n",
    "\n",
    "classification pipeline:\n",
    "\n",
    "$\\rightarrow$ [email] $\\rightarrow$ [model] $\\rightarrow$ [spam or not]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(\n",
    "        str.maketrans('', '', string.punctuation)\n",
    "    )\n",
    "    text = [word for word in text.split()\n",
    "             if word.lower() not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(X, y, test_size=.3) -> Tuple[\n",
    "    Annotated[np.ndarray, 'X_train'],\n",
    "    Annotated[np.ndarray, 'X_test'],\n",
    "    Annotated[np.ndarray, 'y_train'],\n",
    "    Annotated[np.ndarray, 'y_test'],\n",
    "]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=2447,)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X = df.copy()\n",
    "y = X.pop('label')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179, 1) (4179,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4649    0\n",
       "847     0\n",
       "5045    0\n",
       "1101    0\n",
       "5209    0\n",
       "       ..\n",
       "2489    0\n",
       "4835    0\n",
       "1196    0\n",
       "4994    0\n",
       "896     0\n",
       "Name: label, Length: 4179, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing step removes punctuation and stopwords as they do not provide any useful information to the model.\n",
    "\n",
    "**Q: why stopwords are useless to NLP models?**\n",
    "\n",
    "**A: Stopwords appear often in text and they do not provide much information for how much they appear and stopword removage is kind of data normalization step.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development\n",
    "Since this is a classification model will use logistic regression as the first algorithm alongside a dummy classifier as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy = most_frequent, has f1_score = 0.0\n",
      "Strategy = prior, has f1_score = 0.0\n",
      "Strategy = stratified, has f1_score = 0.11931818181818182\n",
      "Strategy = uniform, has f1_score = 0.22482435597189696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy      import DummyClassifier\n",
    "from sklearn.base       import ClassifierMixin\n",
    "from sklearn.metrics    import f1_score, accuracy_score\n",
    "# search for best dummy classifier\n",
    "def make_dummy_cls() -> ClassifierMixin:\n",
    "    '''\n",
    "    This function returns the higest scoring classifier amongest the dummy classifier strategies which are:\n",
    "        * most_frequent\n",
    "        * prior\n",
    "        * stratified\n",
    "        * uniform\n",
    "        * constant\n",
    "    '''\n",
    "    strategies = 'most_frequent prior stratified uniform'.split()\n",
    "    for strategy in strategies:\n",
    "        cls = DummyClassifier(strategy=strategy, random_state=2447)\n",
    "        cls.fit(X_train, y_train)\n",
    "        y_hat = cls.predict(X_test)\n",
    "        print(f'Strategy = {strategy}, has f1_score = {f1_score(y_test, y_hat)}')\n",
    "make_dummy_cls()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
